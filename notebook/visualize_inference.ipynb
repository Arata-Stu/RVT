{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from config.modifier import dynamically_modify_train_config\n",
    "from modules.utils.fetch import fetch_data_module, fetch_model_module\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "def visualize_image(image, title=None):\n",
    "    \"\"\"\n",
    "    可視化のための画像を表示する関数。\n",
    "    \n",
    "    パラメータ:\n",
    "        image: numpy配列またはtorch.Tensor (C, H, W)\n",
    "        title: 表示するタイトル（オプション）\n",
    "    \"\"\"\n",
    "    # torch.Tensorの場合numpy配列に変換\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.detach().cpu().numpy()\n",
    "    \n",
    "    # (C, H, W) -> (H, W, C) に変換\n",
    "    if image.shape[0] == 3:  # チャンネル数が先頭の場合\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "    \n",
    "    # データをクリップ (特にtorchの可能性を考慮して)\n",
    "    \n",
    "    # 可視化\n",
    "    plt.imshow(image)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def modify_config(config: DictConfig, dt: int = 50):\n",
    "    \n",
    "    config.dataset.path = \"../datasets/pre_gen4\"\n",
    "    config.dataset.ev_repr_name = f\"event_frame_dt={dt}\"\n",
    "    config.dataset.sequence_length = 10\n",
    "    config.dataset.batch_size.train = 1\n",
    "    config.dataset.batch_size.eval = 1 \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = \"param.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = OmegaConf.load(yaml_path)\n",
    "config = modify_config(config)\n",
    "config = dynamically_modify_train_config(config)\n",
    "\n",
    "data_module = fetch_data_module(config=config)\n",
    "data_module.setup(\"test\")\n",
    "\n",
    "model_module = fetch_model_module(config=config)\n",
    "model_module.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.utils.types import DataType\n",
    "from utils.padding import InputPadderFromShape\n",
    "\n",
    "data_iter = iter(test_dataloader)\n",
    "data = next(data_iter)[\"data\"]\n",
    "\n",
    "input_padder = InputPadderFromShape(desired_hw=data[DataType.EV_REPR][0].shape[2:4])\n",
    "\n",
    "ev_tensor_sequence = data[DataType.EV_REPR]\n",
    "sparse_obj_labels = data[DataType.OBJLABELS_SEQ]\n",
    "is_first_sample = data[DataType.IS_FIRST_SAMPLE]\n",
    "token_mask_sequence = data.get(DataType.TOKEN_MASK, None)\n",
    "\n",
    "\n",
    "sequence_len = len(ev_tensor_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tidx in range(sequence_len):\n",
    "    ev_tensors = ev_tensor_sequence[tidx]\n",
    "    ev_tensors = input_padder.pad_tensor_ev_repr(ev_tensors)\n",
    "\n",
    "    visualize_image(ev_tensors.squeeze(0), title=f\"t={tidx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rvt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
